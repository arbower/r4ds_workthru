---
title: "r4ds_ch21_databases"
author: "Andy B. PhD"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document: 
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: hide
    theme: spacelab
---

# Summary

Databases are the common way that all data are stored. Normally, for short or small one off projects you could download a csv. But, this becomes cumbersome everytime we have to re-analyze something because 1) we have to talk to a human 2) mistakes are introduced. Rather, we should be able to reach into the database itself and extract the data we need to do our jobs. 

# Prerequisites

```{r}
# Packages you will need
pacman::p_load(tidyverse, DBI, dbplyr, duckdb, here)
```

# Database Basics

* Database tables are stored on a disk and can be arbitrarily large while data frames are stored in memory and ar fundamentally limited.
* Database tables almost always have indexes. Data frames and tibbles do not have indexes. 
* Databases are designed for rapidly collecting data, not analyzing existing data. 

Databases are run by the Database Managing System (DBMS). There are three basic forms:
* `Client Server` DBMS run on a central server, which you connect to from the client (your computer)
* `Cloud` DBMS (RedShift, Google BigQuery, Snowflake), massive cloud based computer servers
* `In-Process` DBMS, SQLite and duckdb work on your computer

## Connecting to a Database

* You need `DBI` to connect to a database. 
* You will need a distinct package unique to your database (e.g., RPostgres)

Then your first step is to connect to a database: (see in the book)

You might need to do some fiddling and research to figure this out because each is a bit esoteric. 

# In this Book

We will use `duckdb` which creates a database in R and deletes it when you shut R down. SO you always start with a clean slate. 

```{r}
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = here("../data","duckdb"))
```

# Load Some Data

Let's add the mpg and diamonds datasets from ggplot2. If you are using this within a project you should readup on `duckdb_read_csv` and `duckdb_register_arrow` which will help read data directly into your database. 

```{r}
dbWriteTable(con, "mpg", ggplot2::mpg)
dbWriteTable(con, "diamonds", ggplot2::diamonds)
```

# DBI Basics

Let's check out our database to ensure our tables loaded correctly:

```{r}
# check the table structures
dbListTables(con)

# they will read tables as data.frames we would prefer tibbles since they are easier to read
con |> 
  dbReadTable("diamonds") |> 
  as_tibble()
```

Now you can add a little SQL and perform your first query:

```{r}
sql <- "
SELECT 
  carat,
  cut,
  clarity,
  color,
  price
FROM diamonds
WHERE price > 15000
"

# now we can look at the results of our query
as_tibble(dbGetQuery(con, sql))
```

## dbplyr Basics

dbplyr is a backend coding tool. What that means is you write dbplyr and it translates to sql. Other backeds include `dtplyr` and `multiplyr` which writes to data.tables and multiple cores. 

```{r}
# you must use tbl()
diamonds_db <- tbl(con, "diamonds")

diamonds_db
```

You might want to start from your own query rather than the full data base or you might have multiple schemas or hierarchy that you need to extract tables from. 

`diamonds_db <- tbl(con, in_schema("sales", "diamonds"))`
`diamonds_db <- tbl(con, in_catalog("north_america", "sales", "diamonds"))`
`diamonds_db <- tbl(con, sql("SELECT * FROM diamonds"))`

This process is _lazy_ in that it just copies down what you say and the order you say it without executing. 

```{r}
big_diamonds_db <- diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price)

# note the messages (sql) (Database info at the top)
big_diamonds_db
```

You can see the sql code generated by dplyr with the `show_query()` function. If you know dplyr this is a great way to learn sql!

```{r}
big_diamonds_db |> 
  show_query()

```

To get the data back into are you call `collect()`

```{r}
big_diamonds <- big_diamonds_db |> 
  collect()

# a tibble
big_diamonds
```

A good work routine is to extract and filter the data you need using dbplyr and then collect the data to manipulate in R (which makes sense).

# SQL

A little sql throught the lens of dbplyr. We will start with the dbplyr function to copy nycflights13 data (as that's something that comes with the package)

```{r}
dbplyr::copy_nycflights13(con)
```

```{r}
flights <- tbl(con, "flights")
planes <- tbl(con, "planes")
```

# SQL Basics

```{r}
# basic sql select statement
flights |> show_query()
planes |>  show_query()
```

We can filter further with WHERE and ORDER BY

```{r}
flights |> 
  filter(dest == "IAH") |> 
  arrange(dep_delay) |> 
  show_query()
```

## GROUP BY converts the query to a summary, causing aggregation to happen

```{r}
flights |> 
  group_by(dest) |> 
  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |> 
  show_query()
```

## SELECT

SELECT in sql performs the same as select(), mutate(), rename(), relocate(), and, summarize(). SO it's a workhorse. 

select(), rename(), and relocate() are basically 1:1 what select statements do. Essentially, as you do this, there are aspects that make dplyr basic more powerful, but SQL is more efficient. *Note that some of the words are in "type" quotes below (type and year). These are reserved words and would be blue in PostGRESql. 

```{r}
planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  show_query()

planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  rename(year_built = year) |> 
  show_query()

planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  relocate(manufacturer, model, .before = type) |> 
  show_query()
```

mutate() works basically the same but it adds a new select statement.

```{r}
flights |> 
  mutate(
    speed = distance / (air_time / 60)
  ) |> 
  show_query()
```

## FROM

For now we are only looking at individual or singular tables. As such, it's boring. When we get to joins this will get more spicy. 

## GROUP BY

This one is pretty straight forward. 

```{r}
diamonds_db |> 
  group_by(cut) |> 
  summarize(
    n = n(),
    avg_price = mean(price, na.rm = TRUE)
  ) |> 
  show_query()

```

## WHERE

filter() is translated to the where SQL clause:

```{r}

flights |> 
  filter(dest == "IAH" | dest == "HOU") |> 
  show_query()

flights |> 
  filter(arr_delay > 0 & arr_delay < 20) |> 
  show_query()

```

* `|` becomes `or` and `&` becomes `and`
* SQL uses `=` never `==` becuase it doesn't have assignment, so there shouldn't be any issues
* SQL uses `` rather than ""

## IN in SQL is another filter option that is close to %in% in R:

```{r}
flights |> 
  filter(dest %in% c("IAH", "HOU")) |> 
  show_query()
```

* SQL also uses NULL rather than NA. They behave similar except NULLs are silently dropped in math. But, dplyr will warn you. However, is.na will work similar with NULLs

```{r}
flights |> 
  filter(!is.na(dep_delay)) |> 
  show_query()

```

If you filter a variable that you created with a summarize you will generate a `HAVING` statement rather than `WHERE`. This makes sense in how SQL operates. 

```{r}
diamonds_db |> 
  group_by(cut) |> 
  summarize(n = n()) |> 
  filter(n > 100) |> 
  show_query()

```

## ORDER BY

This has a straightforward translation from arrange()

```{r}
flights |> 
  arrange(year, month, day, desc(dep_delay)) |> 
  show_query()
```

# Subqueries

Subqueries are a more advanced way of querying data bases by retrieving values that you calculated in the SELECT statement. You can then place them in the FROM statement. This would also work for any attempts to filter() a variable that you just created. 

```{r}
flights |> 
  mutate(
    year1 = year + 1,
    year2 = year1 + 1
  ) |> 
  show_query()

flights |> 
  mutate(year1 = year + 1) |> 
  filter(year1 == 2014) |> 
  show_query()

```

dbplyr will never translate 100% accurate but over time it is getting better. 


# Joins

The joins are similar. 

```{r}
flights |> 
  left_join(planes |>  rename(year_built = year), by = "tailnum") |> 
  show_query()

```

The main thing to notice: SQL joins use subclauses of the FROM clause to bring in additional tables, using ON to define how the tables are related. You can pretty much guess the SQL equivalent from dplyr joins.

# Other Verbs

dbplyr also translates: `distinct()`, `slice_*()`, and `intersect()`, as well as `pivot_longer()` and `pivot_wider()`

### Exercises

#### 21.1a What is `distinct()` translated to? How about `head()`?

_ANSWER_ distinct is distinct. head is limit.

```{r}
flights |> 
  head(n = 3) |> 
  show_query()

```

#### 21.1b Translate the querys from the book in sql to dplyr

```{r}
flights |> 
  filter(dep_delay < arr_delay) |> 
  show_query()

flights |> 
  mutate(speed = distance / (air_time / 60)) |> 
  show_query()

```

# Functional Translations

So what happens when you use `mean(x)` and `summarize()`?

First, we need to make a few helper functions to help us see what's going on:

```{r}
summarize_query <- function(df, ...){
  df |> 
    summarize(...) |> 
    show_query()
}

mutate_query <- function(df, ...){
  df |> 
    mutate(..., .keep = "none") |> 
    show_query()
}

```


Some summaries are very simple, while others (e.g., median) are much more complex.

```{r}
flights |> 
  group_by(year, month, day) |> 
  summarize_query(
    mean = mean(arr_delay, na.rm = TRUE),
    median = median(arr_delay, na.rm = TRUE)
  )

```

Summary functions become more complicated when you include them within a mutate function beause it turns the SQL into a _window_ function with the verb _OVER_ and _PARTITION BY_

```{r}
flights |> 
  group_by(year, month, day) |> 
  mutate_query(
    mean = mean(arr_delay, na.rm = TRUE)
  )

```

WINDOW functions also have lead and lag functions:

```{r}
flights |> 
  group_by(dest) |> 
  arrange(time_hour) |> 
  mutate_query(
    lead = lead(arr_delay),
    lag = lag(arr_delay)
  )
```

Here, it is vital that you arrange the data because SQL data frames/tables have no inherit order. Without arrange, you may get rows back in random order every time. 

Another important SQL query is CASE WHEN and is basically if_else:

```{r}
flights |> 
  mutate_query(
    description = if_else(arr_delay > 0, "delayed", "on-time")
  )


flights |> 
  mutate_query(
    description = 
      case_when(
        arr_delay < -5 ~"early",
        arr_delay < 5 ~ "on time",
        arr_delay >= 5 ~ "late"
      )
  )
```

There aren't always 1:1 translations, here is an example:

```{r}
flights |> 
  mutate_query(
    description = cut(
      arr_delay,
      breaks = c(-Inf, -5, 5, Inf),
      labels = c("early", "on-time", "late")
    )
  )
```