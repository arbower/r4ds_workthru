---
title: "r4ds_ch23_hierarchical_data"
author: "Andy B. PhD"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document: 
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: hide
    theme: spacelab
---

# Summary

This document will help you work through the steps to data rectangle (i.e., taking hierarchical tree-like data and making it tidy). Many data collected from the web are hierarchical broken up into _lists_ making them a little difficult to work with. 

# Prerequisites

```{r}
pacman::p_load(tidyverse, here, broom, janitor, repurrrsive, jsonlite)
```

# Lists

Lists help you store data that is not homogeneous.

```{r}
x1 <- list(1:4, "a", TRUE)

x1
```


If you inherit a list or create a new list it's often helpful to name the _children_ of a list (e.g., like naming variable columns).


```{r}
x2 <- list(a = 1:2, b = 1:3, c = 1:4)

x2
```

The base r `str()` argument is useful to view lists without taking up so much space.

```{r}
str(x2)

# of course glimpse works much the same
glimpse(x1)
glimpse(x2)
```

# Hierarchy

Lists can contain any other type of objects, including other lists. 

```{r}
x3 <- list(list(1, 2), list(3, 4))

glimpse(x3)

# this is very different from `c()` which creates a flat vector
c(c(1, 2), c(3, 4))

x4 <- c(list(1, 2), list(3, 4))

glimpse(x4)
```

As lists get more dense `str()` or `glimpse()` get more useful as they allow you view the full structural hierarchy.

```{r}
x5 <- list(1, list(2, list(3, list(4, list(5)))))

str(x5)
glimpse(x5)

```

As they get even longer glimpse and str will begin to fail (you see glimpse fail above). When that happens, you need `View()`

```{r}
#View(x5)
```

# List Columns

Lists can also live inside a tibble. They are used often in tidymodels framework because they enable you to place model outples, and resamples in the same dataframe. 

```{r}
df <- tibble(
  x = 1:2,
  y = c("a", "b"),
  z = list(list(1, 2), list(3, 4))
)

str(df)

```

There is nothing special about lists in a df or tibble, they behave the same as any other data type:

```{r}
df |> 
  filter(x == 1)

```

Computing with lists is much harder. We will focus on that later; for now, let's just focus on "unnesting" lists. 

# Unnesting

When the _children_ of a list are named, then the columns will just have those names. When they aren't named, you should pay close attention to naming them. 

```{r}
df1 <- tribble(
  ~x, ~y,
  1, list(a = 11, b = 12),
  2, list(a = 21, b = 22),
  3, list(a = 31, b = 32)
)

str(df1)

df2 <- tribble(
  ~x, ~y,
  1, list(11, 12, 13),
  2, list(21),
  3, list(31, 32)
)

str(df2)
```

tidyr provides two arguments to deal with this: `unnest_wider()` and `unnest_longer()`

## unnest_wider()


```{r}
df1 |> 
  unnest_wider(y)
```

You could use another argument to change the names (as you can see they just defaulted above)


```{r}
df1 |> 
  unnest_wider(y, names_sep = "_")

```

## unnest_longer()

```{r}
df2 |> 
  unnest_longer(y)

```

What happens if one of the corresponding rows in x would be empty? Here you can see it duplicated. 

```{r}
df6 <- tribble(
  ~x, ~y,
  "a", list(1, 2),
  "b", list(3),
  "c", list()
)

df6 |> 
  unnest_longer(y)

```
You can see that you lost that data. So if you KNOW that one of your rows or lists is missing data you need to add an NA treatment.

```{r}
df6 |> 
  unnest_longer(y, keep_empty = TRUE)

```

# Inconsistent Types

What happens when you unnest a list had different types of data? 

```{r}
df4 <- tribble(
  ~x, ~y,
  "a", list(1),
  "b", list("a", TRUE, 5)
)

df4 |> 
  unnest_longer(y)
```

You can see in the output that now every output in y is a list of a unique data type. This adheres to the tidyverse principles. 

# Other Functions

* `unnest_auto()` - will automatically choose _longer, or _wider for you.
* `unnest()` - will do both when you have a 2D object, which we won't cover in the book, but we will in other tidy books (tidy models)

### Exercises

#### 23.1a What happens when you use unnest_wider() with unnamed list columns like df2? What argument is now necessary? What ahppens to missing values?

```{r}
df1 <- tribble(
  ~x, ~y,
  1, list(b = 12),
  2, list(b = 22),
  3, list(NULL)
)

str(df1)

# You need this argument
df1 |> 
  unnest_wider(y, names_sep = "_")
```

#### 23.2a What happens when you use unnest_longer() with named list columns like df1? What additional information do you get in the output? How can you suppress that extra detail? 


```{r}
df1 <- tribble(
  ~x, ~y,
  1, list(a = 11, b = 12),
  2, list(a = 21, b = 22),
  3, list(a = 31, b = 32)
)

# you get an extra column for the indices, just add this
df1 |> 
  unnest_longer(y, indices_include = FALSE)

```

#### 23.3a From time to time you encounter data frames with multiple list columns with aligned values. For example, in the following data frame, the values of y and z are aligned (i.e., y and z will always have the same length within a row, and the first value of y corresponds to the first value of z). What happens if you apply two unnest_longer() calls to this data frame? How can you preseve the relationship between x and y? (HINT: carefully read the docs)


```{r}
df4 <- tribble(
  ~x, ~y, ~z,
  "a", list("y-a-1", "y-a-2"), list("z-a-1", "z-a-2"),
  "b", list("y-b-1", "y-b-2"), list("z-b-1", "z-b-2")
)

str(df4)

# boom
df4 |> 
  unnest_longer(c(y, z))
```

# Case Studies

The toy examples above give a sense of what you can do, but they are not as complicated as what you will encounter in the wild. The following case studies will give a better sense of the nested structure of data. 

## Very Wide Data

```{r}
# this is huge
View(gh_repos)

# they call this json for reasons later discussed
repos <- tibble(json = gh_repos)

glimpse(repos) # this was a terrible view
str(repos) # this took like 15 seconds
repos # this lets you know what's up with this file
```

We find out that each of these 6 rows contain an _unnamed_ list of 26-40 rows. Since all rows are unnamed let's start off with `unnest_longer()`

```{r}
repos |> 
  unnest_longer(json)

```

While this might not seem like a big deal what we have done is _named_ each column so we can use `unnest_wider()`

```{r}
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json)

```

But, this is still unwieldy:

```{r}
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json) |> 
  names() |> 
  head(10)

# so let's make a smaller dataset pulling out interesting looking columns
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json) |> 
  select(id, full_name, owner, description) 

```

From the above output we can see the general structure of the file we are dealing with. But, let's unnest further:

```{r}
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json) |> 
  select(id, full_name, owner, description) |> 
  unnest_wider(owner, names_sep = "_")
```

Lots and lots of information about the owner of each repository. 

## Relational Data

You can also have nested data that would normally be relational (SQL-like). Here w look at the characters across Game of Thrones TV and Books. 

```{r}
chars <- tibble(json = got_chars)

chars

```

In this case, there are _named_ elements in the lists so we only have to widen rather than lengthen then widen as above. Then, let's shorten to some meaningful data we might care about.

```{r}
characters <- chars |> 
  unnest_wider(json) |> 
  select(id, name, gender, culture, born, died, alive) 

characters
```


This dataset also has many list columns, one way of looking at them is the following:

```{r}
chars |> 
  unnest_wider(json) |> 
  select(id, where(is.list))

```

Let's explore the `titles` column, which is unnamed, so we will use the unnest into rows

```{r}
chars |> 
  unnest_wider(json) |> 
  select(id, titles) |> 
  unnest_longer(titles)

```

So, might think that you could turn these data into it's own table then join to the other like a sql database: and you're correct. Let's do that here. 

```{r}
titles <- chars |> 
  unnest_wider(json) |> 
  select(id, titles) |> 
  unnest_longer(titles) |> 
  filter(titles != "") |> 
  rename(title = titles)

titles

```

So, you can imagine continuing this for each of teh nested data and then joining the data as you need. And that's a strategy for working with data such as these. 

## Deeply Nested

In this example we will look at data that requires many unnest_wider unnest_longer calls. Googles cities maps.

```{r}
gmaps_cities

```
```{r}
gmaps_cities |> 
  unnest_wider(json)

```

Here we are going to ignore all the rows with `Status != OK` but normally, you'd want to check that. Here, we are dealing with unnamed internal columns so we can go with `unnest_longer()`

```{r}
locations <- gmaps_cities |> 
  unnest_wider(json) |> 
  select(-status) |> 
  unnest_longer(results) |> 
  unnest_wider(results)

```

You can see lots of interesing facets of these data. What we will do here is look closer at the geometry column

```{r}
locations |> 
  select(city, formatted_address, geometry) |> 
  unnest_wider(geometry)

```

Each time you do this you can get a new set of bounds and locations to decide how you want to rectangularize your data:

```{r}
# here, we look at location
locations |> 
  select(city, formatted_address, geometry) |> 
  unnest_wider(geometry) |> 
  unnest_wider(location)

```

Extracting the bounds takes a few more steps:

```{r}
locations |> 
  select(city, formatted_address, geometry) |> 
  unnest_wider(geometry) |> 
  #focus on the variables of interest
  select(!location:viewport) |> 
  unnest_wider(bounds)
```

We then need to rename the southwest and northeast (the corners of the rectangle) so we can use `names_sep()` to create short but evocative names

```{r}
locations |> 
  select(city, formatted_address, geometry) |> 
  unnest_wider(geometry) |> 
  #focus on the variables of interest
  select(!location:viewport) |> 
  unnest_wider(bounds) |> 
  rename(ne = northeast, sw = southwest) |> 
  unnest_wider(c(ne, sw), names_sep = "_")

```

Once you've discovered the path to get to the components you're interested in, you can extract them directly using another tidyr function `hoist()`

```{r}
# this achieves the same as above I think
locations |> 
  select(city, formatted_address, geometry) |> 
  hoist(
    geometry,
    ne_lat = c("bounds", "northeast", "lat"),
    sw_lat = c("bounds", "southwest", "lat"),
    ne_lon = c("bounds", "northeast", "lng"),
    sw_lon = c("bounds", "southwest", "lng")
  )

```

### Exercises

#### 23.1b Roughly estimate when gh_repos was created. Why can you only roughly estimate the date? 

_Answer_ I think, and I don't really care, because you can only really see the date of the first push. 

```{r}
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json) |> 
  select(id, pushed_at) |> 
  group_by(id) |> 
  mutate(
    first_push = min(pushed_at)
  ) |> 
  arrange(first_push)
```

#### 23.2b The owner column of ge_repo contains a lot of duplicated information because each owner can have many repos. Can you construct an owners dataframe that contains one row for each ownder? (HINT: Does distinct() work with list-cols?)

_Answer_ Yes, I think so. I don't care about this. But, here is my attempt. 

```{r}
repos |> 
  unnest_longer(json) |> 
  unnest_wider(json) |> 
  unnest_wider(owner, names_sep = "_") |>
  select(owner_login, owner_id) |> 
  distinct()
```

#### 23.3b Follow the steps from `titles` with the GOT data above for: aliases, allegiances, books, and TV.


```{r}
#aliases
chars |> 
  unnest_wider(json) |> 
  select(id, aliases) |> 
  unnest_longer(aliases)

#allegiances
chars |> 
  unnest_wider(json) |> 
  select(id, allegiances) |> 
  unnest_longer(allegiances)

#books
chars |> 
  unnest_wider(json) |> 
  select(id, books) |> 
  unnest_longer(books) 

#TV
chars |> 
  unnest_wider(json) |> 
  select(id, tvSeries) |> 
  unnest_longer(tvSeries)
```

#### 23.4b Explain the following code line by line. Why is it interesting? Why does it work for got_chars but not work in general?

_Answer_ becauase all the list-cols are named?
```{r}
tibble(json = got_chars) |> 
  unnest_wider(json) |> 
  select(id, where(is.list)) |> 
  pivot_longer(
    where(is.list),
    names_to = "name",
    values_to = "value"
  ) |> 
  unnest_longer(value)

```

#### 23.5b In gmaps_cities what does address_components contain? WHy does the length vary betrween rows? Unnest it appropriately to figure it out. (HINT: types always appears to contain two elements. Does unnest_wider() make it easier to work with than unnest_longer())?

```{r}
gmaps_cities |> 
  unnest_wider(json) |> 
  unnest_longer(results) |> 
  unnest_wider(results, names_sep = "_") |> 
  unnest_longer(starts_with('results_address_comp')) |> 
  unnest_wider(starts_with('results_address_comp')) |> 
  unnest_longer(types) |> 
  unnest_wider(types, names_sep = "_")
```
# JSON

JavaScript Object Notation (JSON) and R are not perfect one-to-one so it's important to know when JSON doesn't work in R so you know how to trouble shoot. 

# Data Types 

JSON is a simple format designed to be easily read and written by machines, not humans. It has six key data types. 

* The simplest type is null (null), which plays the same role as NA in R. It represents the absence of data. 
* A string is much like a string in R, but must always use "double quotes"
* A number is similar to Rs numbers: they can use integer (e.g., 112), decimal (e.g., 123.45), or scientific (e.g., 1.23e3) notation. JSON does not support Inf -Inf or NaN.
* A boolean is similar to R's TRUE and FALSE but uses lowercase true and false
* An array, is like an unnamed list and is written with [] (e.g., [1, 2, 3] or [null, 1, "string"])
* An object, is like a named list and is written with {} (e.g., {"X":1, "Y":2})

Note, JSON does not have a native way to deal with dates or times, so you generally need to use `readr::parse_date()` from strings

Likewise, `readr::parse_double()` will be helpful for floating point data. 

# jsonlite

To convert JSON in to R format, you should use `jsonlite` package. Most often you will use a path to a json file so here `read_json()`. But, you will also use `parse_json()`

```{r}

str(parse_json('1'))

str(parse_json('[1, 2, 3]'))

str(parse_json('{"x": [1, 2, 3]}'))
```

# Starting the Rectangling Process

In most cases, JSON files contain a single top-level array, because they're designed to provide data about multiple "things", e.g., multiple pages, multiple records, or multiple results. 

In this case you will start the rectangling process with `tibble(json)`

```{r}
json <- '[
{"name": "John", "age": 34},
{"name": "Susan", "age": 27}
]'

str(json)

df <- tibble(json = parse_json(json))

df |> 
  unnest_wider(json)
```

In rarer cases, the JSON file consists of a single top-level JSON object, representing one "thing." In this case you'll need to kick off the rectangling process by wrapping it in a list, before you put it in a tibble:

```{r}
json <- '{
"status": "OK",
"results": [
  {"name": "John", "age": 35},  
  {"name": "Susan", "age": 27}
  ]
}'

str(json)

df <- tibble(json = list(parse_json(json)))

df |> 
  unnest_wider(json) |> 
  unnest_longer(results) |> 
  unnest_wider(results)
```

Or, alternatively, you can reach into the JSON file directly and extract the bit you really care about:

```{r}

df <- tibble(results = parse_json(json)$results)

df |> 
  unnest_wider(results)
```

### Exercises

#### 23.1c Rectangle the follow df_col and df_row. They represent the two ways of encoding a data frame in JSON.

```{r}
json_col <- parse_json('
{
"x": ["a", "x", "z"],
"y": [10, null, 3]
}
')

json_row <- parse_json('
[
{"x": "a", "y": 10},
{"x": "x", "y": null},
{"x": "z", "y": 3}
]
')

df_col <- tibble(json = list(json_col))
df_row <- tibble(json = json_row)

str(df_col)

# df_col

df_col |> 
  unnest_wider(json) |> 
  unnest_longer(c(x, y))

#  df_row
df_row |> 
  unnest_wider(json)
```



